# LLM Prompting

Skills: LLMs, Prompt Engineering, Inference APIs

Objective:
Learn how to interact with large language models effectively to produce structured, accurate, and controllable outputs.

What to learn:
- System vs user prompts and instruction hierarchy
- Few-shot prompting and prompt templates
- Structured outputs (JSON, schemas)
- Controlling verbosity, tone, and hallucination

How to prove:
- Build prompt templates for multiple use cases
- Enforce structured output using schemas
- Compare outputs across different prompts

Tools:
- Groq / OpenAI / Gemini APIs
- LangChain prompt templates
- JSON schema validation
